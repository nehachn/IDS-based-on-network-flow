{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kexCg_6QyJBr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3WoFtiqKf2G"
      },
      "source": [
        "#Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyob8NTW6XRC"
      },
      "source": [
        "# read & manipulate data\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "# visualisations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid', context='notebook')\n",
        "%matplotlib notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23pCunA9Ksjz"
      },
      "source": [
        "# misc\n",
        "import random as rn\n",
        "\n",
        "# manual parameters\n",
        "RANDOM_SEED = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8W8Ff8SMO7g"
      },
      "source": [
        "#Train/test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25EXoLk_xgMO"
      },
      "source": [
        "df_ = pd.read_csv(\"/content/drive/MyDrive/cicids2017 dataset/all_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8WvxyIsMSS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5887f4-9508-4cb3-997b-9b06130d8bb8"
      },
      "source": [
        "attack = df_[df_.anomaly == 1]\n",
        "normal = df_[df_.anomaly == 0]\n",
        "attack = attack.drop('Label', axis=1)\n",
        "normal = normal.drop('Label', axis=1)\n",
        "print(f\"\"\"Shape of the datasets:\n",
        "    clean (rows, cols) = {normal.shape}\n",
        "    fraud (rows, cols) = {attack.shape}\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the datasets:\n",
            "    clean (rows, cols) = (2271320, 80)\n",
            "    fraud (rows, cols) = (556556, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyNMNhY2MVbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e904a8-4bd6-41ab-952f-b4cda793158a"
      },
      "source": [
        "# shuffle our training set\n",
        "normal = normal.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "#TRAINING_SAMPLE= math.ceil(normal.shape[0]*(20/100))\n",
        "TRAINING_SAMPLE = normal.shape[0] - attack.shape[0]\n",
        "\n",
        "print(f\"\"\"training sample size: {TRAINING_SAMPLE} and normal case size: {normal.shape[0]} left out normals: {normal.shape[0]-TRAINING_SAMPLE}\"\"\")\n",
        "\n",
        "# training set: exlusively normal samples\n",
        "X_train_all = normal.iloc[:TRAINING_SAMPLE].drop('anomaly', axis=1)\n",
        "\n",
        "# testing  set: the remaining normal + all the attack samples\n",
        "X_test = normal.iloc[TRAINING_SAMPLE:].append(attack).sample(frac=1)\n",
        "\n",
        "print(f\"\"\"Our testing set is composed as follows:\n",
        "{X_test.anomaly.value_counts()}\"\"\")\n",
        "print(f\"\"\"Class ratio in testing set is composed as follows:\n",
        "{X_test.anomaly.value_counts(normalize=True)*100}\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training sample size: 1714764 and normal case size: 2271320 left out normals: 556556\n",
            "Our testing set is composed as follows:\n",
            "1    556556\n",
            "0    556556\n",
            "Name: anomaly, dtype: int64\n",
            "Class ratio in testing set is composed as follows:\n",
            "1    50.0\n",
            "0    50.0\n",
            "Name: anomaly, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzbEbALbMjau"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "RANDOM_SEED = 42\n",
        "VALIDATE_SIZE = 0.3\n",
        "\n",
        "# train // validate - no labels since they're all clean anyway\n",
        "X_train, X_validate = train_test_split(X_train_all, \n",
        "                                       test_size=VALIDATE_SIZE, \n",
        "                                       random_state=RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKMEJQDbEYXq"
      },
      "source": [
        "# manually splitting the labels from the test df\n",
        "X_test, y_test = X_test.drop('anomaly', axis=1).values, X_test.anomaly.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn7OmsEaNM2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94ac03f-0e76-4174-ab16-570422c36d8c"
      },
      "source": [
        "print(f\"\"\"Shape of the datasets:\n",
        "    training (rows, cols) = {X_train.shape}\n",
        "    validate (rows, cols) = {X_validate.shape}\n",
        "    holdout  (rows, cols) = {X_test.shape}\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the datasets:\n",
            "    training (rows, cols) = (1200334, 79)\n",
            "    validate (rows, cols) = (514430, 79)\n",
            "    holdout  (rows, cols) = (1113112, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMZeTo41ESMF"
      },
      "source": [
        "#Normalising & Standardising"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tqTD4PsEdnQ"
      },
      "source": [
        "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# configure our pipeline\n",
        "pipeline = Pipeline([('normalizer', Normalizer()),\n",
        "                     ('scaler', MinMaxScaler())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f9a-t4QEjYq"
      },
      "source": [
        "# get normalization parameters by fitting to the training data\n",
        "pipeline.fit(X_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyF8-1aWEnAk"
      },
      "source": [
        "# transform the training and validation data with these parameters\n",
        "X_train_transformed = pipeline.transform(X_train)\n",
        "X_validate_transformed = pipeline.transform(X_validate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGhqM2o7E51r"
      },
      "source": [
        "#Training the Variational autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtUgwOCIzzlq"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras import regularizers\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import initializers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTxb5T4NZuBz"
      },
      "source": [
        "# data dimensions // hyperparameters \n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "BATCH_SIZE = 8192\n",
        "EPOCHS = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEpFP9FfS1P4"
      },
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a point.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "held2x6STfQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a4fd66-b1f0-4c57-9dbd-02c220bd04cd"
      },
      "source": [
        "latent_dim = 64\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(input_dim,))\n",
        "x = layers.Dense(512, activation=\"tanh\")(encoder_inputs)\n",
        "x = layers.Dense(512, activation=\"tanh\")(x)\n",
        "x = layers.Dense(256,  activation=\"tanh\")(x)\n",
        "\n",
        "\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 79)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          40960       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          262656      dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          131328      dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 64)           16448       dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 64)           16448       dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sampling (Sampling)             (None, 64)           0           z_mean[0][0]                     \n",
            "                                                                 z_log_var[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 467,840\n",
            "Trainable params: 467,840\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNWtv3n1LgfA",
        "outputId": "2728e9b9-1772-4c30-a1e5-d56beb8dfcfd"
      },
      "source": [
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(256, activation=\"tanh\")(latent_inputs)\n",
        "x = layers.Dense(512, activation=\"tanh\")(x)\n",
        "x = layers.Dense(512, activation=\"tanh\")(x)\n",
        "decoder_outputs = layers.Dense(input_dim, activation= \"tanh\")(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 64)]              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 79)                40527     \n",
            "=================================================================\n",
            "Total params: 451,407\n",
            "Trainable params: 451,407\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBpUFWRGM5om"
      },
      "source": [
        "Define VAE as model with a custom train_step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAw-BoDDMzGS"
      },
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "        self.built = True\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction))\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpT5LtJjNlgM"
      },
      "source": [
        "Train the VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db8Dq8apNoAr"
      },
      "source": [
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b6u-QA3a3Jo",
        "outputId": "f5378065-e660-4537-b91e-25b5f08eecd5"
      },
      "source": [
        "history = vae.fit(\n",
        "    X_train_transformed, \n",
        "    shuffle=True,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        ");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "147/147 [==============================] - 4s 18ms/step - loss: 1558.7266 - reconstruction_loss: 1028.7924 - kl_loss: 37.8914\n",
            "Epoch 2/100\n",
            "147/147 [==============================] - 3s 18ms/step - loss: 765.5536 - reconstruction_loss: 727.0952 - kl_loss: 25.1740\n",
            "Epoch 3/100\n",
            "147/147 [==============================] - 3s 18ms/step - loss: 730.5480 - reconstruction_loss: 703.4915 - kl_loss: 19.8685\n",
            "Epoch 4/100\n",
            "147/147 [==============================] - 3s 18ms/step - loss: 714.7534 - reconstruction_loss: 692.9023 - kl_loss: 16.1024\n",
            "Epoch 5/100\n",
            "147/147 [==============================] - 3s 18ms/step - loss: 705.4604 - reconstruction_loss: 687.2036 - kl_loss: 14.1898\n",
            "Epoch 6/100\n",
            "147/147 [==============================] - 3s 18ms/step - loss: 700.2109 - reconstruction_loss: 683.5845 - kl_loss: 13.0596\n",
            "Epoch 7/100\n",
            "147/147 [==============================] - 3s 18ms/step - loss: 696.4513 - reconstruction_loss: 681.0989 - kl_loss: 12.4960\n",
            "Epoch 8/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 694.7375 - reconstruction_loss: 679.3649 - kl_loss: 12.1485\n",
            "Epoch 9/100\n",
            "147/147 [==============================] - 3s 18ms/step - loss: 693.2212 - reconstruction_loss: 678.0829 - kl_loss: 11.9271\n",
            "Epoch 10/100\n",
            "147/147 [==============================] - 3s 18ms/step - loss: 691.0045 - reconstruction_loss: 677.0225 - kl_loss: 11.7169\n",
            "Epoch 11/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 690.1940 - reconstruction_loss: 676.2695 - kl_loss: 11.5453\n",
            "Epoch 12/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 688.8142 - reconstruction_loss: 675.5649 - kl_loss: 11.3975\n",
            "Epoch 13/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 688.9319 - reconstruction_loss: 675.0764 - kl_loss: 11.2811\n",
            "Epoch 14/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 688.3059 - reconstruction_loss: 674.5739 - kl_loss: 11.1424\n",
            "Epoch 15/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 687.5647 - reconstruction_loss: 674.1281 - kl_loss: 10.9954\n",
            "Epoch 16/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 687.3025 - reconstruction_loss: 673.8781 - kl_loss: 10.9040\n",
            "Epoch 17/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 686.6079 - reconstruction_loss: 673.5524 - kl_loss: 10.7687\n",
            "Epoch 18/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 686.3129 - reconstruction_loss: 673.0950 - kl_loss: 10.6349\n",
            "Epoch 19/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 685.0993 - reconstruction_loss: 672.8273 - kl_loss: 10.5218\n",
            "Epoch 20/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 685.1110 - reconstruction_loss: 672.6001 - kl_loss: 10.4217\n",
            "Epoch 21/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 684.7305 - reconstruction_loss: 672.4130 - kl_loss: 10.3291\n",
            "Epoch 22/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 685.1389 - reconstruction_loss: 672.2048 - kl_loss: 10.2458\n",
            "Epoch 23/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 684.7402 - reconstruction_loss: 671.9529 - kl_loss: 10.1653\n",
            "Epoch 24/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 684.7675 - reconstruction_loss: 671.8063 - kl_loss: 10.1232\n",
            "Epoch 25/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 683.8730 - reconstruction_loss: 671.6157 - kl_loss: 10.0519\n",
            "Epoch 26/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 684.2685 - reconstruction_loss: 671.5878 - kl_loss: 10.0118\n",
            "Epoch 27/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.5201 - reconstruction_loss: 671.3074 - kl_loss: 9.9527\n",
            "Epoch 28/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 745.9818 - reconstruction_loss: 694.5072 - kl_loss: 18.1622\n",
            "Epoch 29/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 689.6091 - reconstruction_loss: 675.0578 - kl_loss: 11.2372\n",
            "Epoch 30/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 686.7873 - reconstruction_loss: 673.3880 - kl_loss: 10.7478\n",
            "Epoch 31/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 685.6792 - reconstruction_loss: 672.7427 - kl_loss: 10.4927\n",
            "Epoch 32/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 685.2185 - reconstruction_loss: 672.3351 - kl_loss: 10.3337\n",
            "Epoch 33/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 684.5700 - reconstruction_loss: 671.9894 - kl_loss: 10.2052\n",
            "Epoch 34/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 684.5659 - reconstruction_loss: 671.7872 - kl_loss: 10.1155\n",
            "Epoch 35/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 683.2705 - reconstruction_loss: 671.5508 - kl_loss: 10.0296\n",
            "Epoch 36/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 684.0542 - reconstruction_loss: 671.4088 - kl_loss: 9.9637\n",
            "Epoch 37/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 683.8317 - reconstruction_loss: 671.2723 - kl_loss: 9.9033\n",
            "Epoch 38/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.6720 - reconstruction_loss: 671.0874 - kl_loss: 9.8373\n",
            "Epoch 39/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.9925 - reconstruction_loss: 671.0532 - kl_loss: 9.7959\n",
            "Epoch 40/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.7893 - reconstruction_loss: 670.8624 - kl_loss: 9.7232\n",
            "Epoch 41/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 728.2435 - reconstruction_loss: 688.1417 - kl_loss: 15.4292\n",
            "Epoch 42/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 685.7504 - reconstruction_loss: 672.7493 - kl_loss: 10.5936\n",
            "Epoch 43/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 684.2929 - reconstruction_loss: 671.7898 - kl_loss: 10.1787\n",
            "Epoch 44/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 683.5184 - reconstruction_loss: 671.3538 - kl_loss: 10.0008\n",
            "Epoch 45/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 683.1831 - reconstruction_loss: 671.0923 - kl_loss: 9.8938\n",
            "Epoch 46/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.9822 - reconstruction_loss: 670.9273 - kl_loss: 9.8197\n",
            "Epoch 47/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.9738 - reconstruction_loss: 670.7545 - kl_loss: 9.7498\n",
            "Epoch 48/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 683.9960 - reconstruction_loss: 670.8259 - kl_loss: 9.7140\n",
            "Epoch 49/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.0830 - reconstruction_loss: 670.5473 - kl_loss: 9.6457\n",
            "Epoch 50/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.6920 - reconstruction_loss: 670.4651 - kl_loss: 9.6144\n",
            "Epoch 51/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.8896 - reconstruction_loss: 670.3945 - kl_loss: 9.5624\n",
            "Epoch 52/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.9545 - reconstruction_loss: 670.3665 - kl_loss: 9.5442\n",
            "Epoch 53/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.3508 - reconstruction_loss: 670.2431 - kl_loss: 9.4954\n",
            "Epoch 54/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.1578 - reconstruction_loss: 670.1770 - kl_loss: 9.4728\n",
            "Epoch 55/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 683.4874 - reconstruction_loss: 670.4760 - kl_loss: 9.4822\n",
            "Epoch 56/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.4679 - reconstruction_loss: 670.0502 - kl_loss: 9.4081\n",
            "Epoch 57/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 680.8926 - reconstruction_loss: 670.0270 - kl_loss: 9.3975\n",
            "Epoch 58/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.7167 - reconstruction_loss: 670.0037 - kl_loss: 9.3639\n",
            "Epoch 59/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.6993 - reconstruction_loss: 669.9550 - kl_loss: 9.3368\n",
            "Epoch 60/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.2541 - reconstruction_loss: 669.9455 - kl_loss: 9.3204\n",
            "Epoch 61/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.6729 - reconstruction_loss: 669.8860 - kl_loss: 9.2926\n",
            "Epoch 62/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.1882 - reconstruction_loss: 669.8026 - kl_loss: 9.2615\n",
            "Epoch 63/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.8442 - reconstruction_loss: 669.9617 - kl_loss: 9.2709\n",
            "Epoch 64/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.2015 - reconstruction_loss: 669.7092 - kl_loss: 9.2236\n",
            "Epoch 65/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.2932 - reconstruction_loss: 669.7173 - kl_loss: 9.2298\n",
            "Epoch 66/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 680.8627 - reconstruction_loss: 669.6492 - kl_loss: 9.1855\n",
            "Epoch 67/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 733.5012 - reconstruction_loss: 691.8229 - kl_loss: 16.8907\n",
            "Epoch 68/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 688.1650 - reconstruction_loss: 673.5939 - kl_loss: 11.1338\n",
            "Epoch 69/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 685.5763 - reconstruction_loss: 672.1425 - kl_loss: 10.4301\n",
            "Epoch 70/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 684.0097 - reconstruction_loss: 671.5066 - kl_loss: 10.0803\n",
            "Epoch 71/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 683.6509 - reconstruction_loss: 671.1421 - kl_loss: 9.8626\n",
            "Epoch 72/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 683.1753 - reconstruction_loss: 670.7513 - kl_loss: 9.7036\n",
            "Epoch 73/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.9954 - reconstruction_loss: 670.7240 - kl_loss: 9.6219\n",
            "Epoch 74/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.3054 - reconstruction_loss: 670.3753 - kl_loss: 9.5064\n",
            "Epoch 75/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.5205 - reconstruction_loss: 670.2999 - kl_loss: 9.4399\n",
            "Epoch 76/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.4108 - reconstruction_loss: 670.1798 - kl_loss: 9.3861\n",
            "Epoch 77/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.8022 - reconstruction_loss: 670.1016 - kl_loss: 9.3414\n",
            "Epoch 78/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.1547 - reconstruction_loss: 669.9840 - kl_loss: 9.3095\n",
            "Epoch 79/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.6527 - reconstruction_loss: 669.9878 - kl_loss: 9.2691\n",
            "Epoch 80/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.1506 - reconstruction_loss: 669.8806 - kl_loss: 9.2480\n",
            "Epoch 81/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.1973 - reconstruction_loss: 669.9297 - kl_loss: 9.2338\n",
            "Epoch 82/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.8955 - reconstruction_loss: 669.7871 - kl_loss: 9.1993\n",
            "Epoch 83/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.4129 - reconstruction_loss: 669.7014 - kl_loss: 9.1762\n",
            "Epoch 84/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.1531 - reconstruction_loss: 669.6873 - kl_loss: 9.1601\n",
            "Epoch 85/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.0662 - reconstruction_loss: 669.5984 - kl_loss: 9.1330\n",
            "Epoch 86/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.4709 - reconstruction_loss: 669.6553 - kl_loss: 9.1388\n",
            "Epoch 87/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.3889 - reconstruction_loss: 669.5500 - kl_loss: 9.1042\n",
            "Epoch 88/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 680.9457 - reconstruction_loss: 669.5456 - kl_loss: 9.0938\n",
            "Epoch 89/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 680.9802 - reconstruction_loss: 669.4618 - kl_loss: 9.0640\n",
            "Epoch 90/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.3095 - reconstruction_loss: 669.5272 - kl_loss: 9.0552\n",
            "Epoch 91/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 680.0328 - reconstruction_loss: 669.4669 - kl_loss: 9.0588\n",
            "Epoch 92/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.1221 - reconstruction_loss: 669.4142 - kl_loss: 9.0282\n",
            "Epoch 93/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 679.9902 - reconstruction_loss: 669.3778 - kl_loss: 9.0200\n",
            "Epoch 94/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 680.2598 - reconstruction_loss: 669.3463 - kl_loss: 9.0128\n",
            "Epoch 95/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 682.7737 - reconstruction_loss: 669.9615 - kl_loss: 9.1460\n",
            "Epoch 96/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 680.5060 - reconstruction_loss: 669.2394 - kl_loss: 8.9923\n",
            "Epoch 97/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.4830 - reconstruction_loss: 669.2588 - kl_loss: 8.9889\n",
            "Epoch 98/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 680.6732 - reconstruction_loss: 669.2711 - kl_loss: 8.9690\n",
            "Epoch 99/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 680.0577 - reconstruction_loss: 669.2388 - kl_loss: 8.9738\n",
            "Epoch 100/100\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 681.1978 - reconstruction_loss: 669.3100 - kl_loss: 8.9808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kexCg_6QyJBr"
      },
      "source": [
        "#Save the model the model weitghts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGUlszidielq"
      },
      "source": [
        "vae.save_weights('/content/drive/MyDrive/cicids2017 dataset/vae_tanh,tanh+softmax,adam,512,512,256,64_EPHOCHES_100_b8192.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMIGIAc3yNWL"
      },
      "source": [
        "#Load the model weights\n",
        "run upto vae compile then :\n",
        "\n",
        "      first add structure of vae to new_model \n",
        "      then add saved model weights into the new_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvmHmcbWitdq"
      },
      "source": [
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "vae.load_weights('/content/drive/MyDrive/cicids2017 dataset/vae_tanh,tanh+softmax,adam,512,512,256,64_EPHOCHES_100_b8192.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwNMV7PYw7f0",
        "outputId": "9029e6b3-8980-4b8f-df7a-63ce7916fc22"
      },
      "source": [
        "vae.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder (Functional)         [(None, 64), (None, 64),  467840    \n",
            "_________________________________________________________________\n",
            "decoder (Functional)         (None, 79)                451407    \n",
            "=================================================================\n",
            "Total params: 919,253\n",
            "Trainable params: 919,247\n",
            "Non-trainable params: 6\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqVbbnZsF5rV"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ1L8WeWLczQ"
      },
      "source": [
        "# transform the test set with the pipeline fitted to the training set\n",
        "X_test_transformed = pipeline.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1srn3JqZxcN"
      },
      "source": [
        "_, _, reconstructed_sample= vae.encoder.predict(X_test_transformed, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxqCuYhKbPCe"
      },
      "source": [
        "reconstructed_x = vae.decoder.predict(reconstructed_sample,batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVMIOjCNbODQ"
      },
      "source": [
        "# MSE and plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjgllvWzGsCe"
      },
      "source": [
        "# calculating the mean squared error reconstruction loss per row in the numpy array\n",
        "mse = np.mean(np.power(X_test_transformed - reconstructed_x, 2), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3rh1I-cAjin"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GF0RLDGG0nG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "841a4a8e-9349-4e20-ad73-fab8e8c023b3"
      },
      "source": [
        "normal_ = mse[y_test==0]\n",
        "attack_ = mse[y_test==1]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "\n",
        "ax.hist(normal_, bins=20, density=True, label=\"normal\", alpha=.6, color=\"green\")\n",
        "ax.hist(attack_, bins=20, density=True, label=\"attack\", alpha=.6, color=\"red\")\n",
        "\n",
        "plt.title(\"(Normalized) Distribution of the Reconstruction Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc3ZWv70unAP"
      },
      "source": [
        "#Unsupervised\n",
        "**Percentiles**\n",
        "\n",
        "We could set this threshold by taking the top x% of the dataset and considering it anomalous.\n",
        "\n",
        "**MAD**\n",
        "\n",
        "We could also use a modified Z-score using the Median Absolute Deviation to define outliers on our reconstruction data. This algorithm is more robust and scalable than the percentiles method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKDz034d47O9"
      },
      "source": [
        "THRESHOLD = 0.5\n",
        "\n",
        "def mad_score(points):\n",
        "    \"\"\"https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm \"\"\"\n",
        "    m = np.median(points)\n",
        "    ad = np.abs(points - m)\n",
        "    mad = np.median(ad)\n",
        "    \n",
        "    return 0.6745 * ad / mad\n",
        "\n",
        "z_scores = mad_score(mse)\n",
        "outliers = z_scores < THRESHOLD\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "FVFQlAZpbLAL",
        "outputId": "e6556e49-9049-4e86-bca0-240173f136e7"
      },
      "source": [
        "clean = z_scores[y_test==0]\n",
        "fraud = z_scores[y_test==1]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "\n",
        "ax.hist(clean, bins=20, density=True, label=\"clean\", alpha=.6, color=\"green\")\n",
        "ax.hist(fraud, bins=20, density=True, label=\"fraud\", alpha=.6, color=\"red\")\n",
        "\n",
        "plt.title(\"Distribution of the modified z-scores\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu8hi6GWvXFC",
        "outputId": "5404e018-d6c7-40ec-cfb3-42d661590207"
      },
      "source": [
        "print(f\"Detected {np.sum(outliers):,} outliers in a total of {np.size(z_scores):,} transactions [{np.sum(outliers)/np.size(z_scores):.2%}].\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected 367,457 outliers in a total of 1,113,112 transactions [33.01%].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FIWZdzRvsgX"
      },
      "source": [
        "#Supervised\n",
        "We know the labels, so we can verify our results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHHZx011zndm",
        "outputId": "9ca7fbe0-2d82-492f-afd8-26ed4aec3c05"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, outliers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.75      0.64    556556\n",
            "           1       0.63      0.41      0.50    556556\n",
            "\n",
            "    accuracy                           0.58   1113112\n",
            "   macro avg       0.60      0.58      0.57   1113112\n",
            "weighted avg       0.60      0.58      0.57   1113112\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g4TCou6iG5N"
      },
      "source": [
        "#AUC curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGKrlys0iG5O"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "mse_score = mse\n",
        "\n",
        "if roc_auc_score(y_test, mse_score)<0.5:\n",
        "    mse_score *= -1\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, mse_score)\n",
        "auc_score = roc_auc_score(y_test, mse_score)\n",
        "fig, ax1 = plt.subplots(1, 1, figsize = (8, 8))\n",
        "ax1.plot(fpr, tpr, 'b.-', label = 'ROC Curve (%2.2f)' %  auc_score)\n",
        "ax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\n",
        "ax1.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOP2K_SCQq6u"
      },
      "source": [
        "mse_score = z_scores\n",
        "\n",
        "if roc_auc_score(y_test, mse_score)<0.5:\n",
        "    mse_score *= -1\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, mse_score)\n",
        "auc_score = roc_auc_score(y_test, mse_score)\n",
        "fig, ax1 = plt.subplots(1, 1, figsize = (8, 8))\n",
        "ax1.plot(fpr, tpr, 'b.-', label = 'ROC Curve (%2.2f)' %  auc_score)\n",
        "ax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\n",
        "ax1.legend();"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}